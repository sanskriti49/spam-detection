# -*- coding: utf-8 -*-
"""spam-detection-model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hSLsVkkIxG-669zALrnsxKTtxhhluG7Z
"""

# importing libraries
import numpy as py
import pandas as pd
from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,precision_score
import matplotlib.pyplot as plt
import seaborn as sns
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer

nltk.download('stopwords')

"""## Importing Dataset"""

url="https://raw.githubusercontent.com/sanskriti49/spam-detection/main/spam.csv"
df=pd.read_csv(url, encoding="ISO-8859-1")
print(df.head())

"""## Label Encoding"""

df = df[['v1', 'v2']]
df = df.rename(columns={'v1': 'label', 'v2': 'message'})

# encode the labels: 'ham' means 0 , 'spam' means 1
df['label']=df['label'].map({'ham':0, 'spam':1})

x=df['message']
y=df['label']

y = y.fillna(y.median())
y = pd.to_numeric(y,errors='coerce')

"""## Data Pre-processing"""

ps=PorterStemmer()
corpus=[]

for i in range(0,len(x)):
  email=re.sub('[^a-zA-Z]',' ',str(x.iloc[i]))
  email=email.lower()
  email=email.split(' ')

  email=[ps.stem(word) for word in email if word not in stopwords.words('english')]
  email=' '.join(email)
  corpus.append(email)

"""## Data transformation"""

# CountVectorizer matrix
# from sklearn.feature_extraction.text import CountVectorizer
# cv=CountVectorizer(max_features=5000)
# x=cv.fit_transform(corpus).toarray()

from sklearn.feature_extraction.text import TfidfVectorizer

tfidf = TfidfVectorizer(stop_words='english',max_features=5000)
x_tfidf = tfidf.fit_transform(corpus).toarray()

"""## Train-Test split"""

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test=train_test_split(x_tfidf,y,test_size=0.25,random_state=0)

# applying MultiNomialNB model
from sklearn.naive_bayes import MultinomialNB
classifier=MultinomialNB().fit(x_train, y_train)

"""## Making predictions and creating a Confusion Matrix"""

y_pred=classifier.predict(x_test)

# creating confusion matrix
# from sklearn.metrics import confusion_matrix
confusion_m=confusion_matrix(y_test,y_pred)
print(confusion_m)

"""## Getting the accuracy"""

accuracy=accuracy_score(y_test,y_pred)
print("Accuracy score of MultinomialNB is: ", accuracy)

# Calculate precision score
precision = precision_score(y_test, y_pred)
print(f"Precision score of MultinomialNB is: {precision}")

"""## Dumping Models"""

import pickle
from google.colab import files

pickle.dump(classifier,open('model.pkl','wb'))
pickle.dump(tfidf,open('tfidf-vectorizer.pkl','wb'))

files.download('model.pkl')
files.download('tfidf-vectorizer.pkl')

final_df = pd.DataFrame({'Subject': df['message'], 'Label': y})
final_df['Label'] = final_df['Label'].map({0: "Not spam", 1: "Spam"})

print(final_df.head())

"""## Pie-chart"""

# Count the occurrences of each label
label_counts = final_df['Label'].value_counts()

# Plot the pie chart
plt.figure(figsize=(7, 7))
plt.pie(label_counts, labels=label_counts.index, autopct='%1.1f%%', colors=['lightgreen', 'lightcoral'], startangle=90, explode=(0.1, 0))
plt.title('Spam vs Not Spam Distribution')
plt.axis('equal')  # Equal aspect ratio ensures that pie chart is drawn as a circle.
plt.show()